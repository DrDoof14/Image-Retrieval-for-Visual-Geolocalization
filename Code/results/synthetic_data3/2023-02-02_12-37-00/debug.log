2023-02-02 12:37:00   Arguments: Namespace(Ensembel=False, aggregation='netvlad', aggregation2='netvlad', backbone='resnet18conv4', brightness=0, cache_refresh_rate=1000, contrast=0, criterion='triplet', dataset_name='pitts30k', datasets_folder='/content', device='cuda', efficient_ram_testing=False, epochs_num=10, fc_output_dim=None, freeze_te=None, horizontal_flip=False, hue=0, infer_batch_size=16, l2='before_pool', lr=1e-05, lr_crn_layer=0.005, lr_crn_net=0.0005, majority_weight=0.01, margin=0.1, mining='partial', neg_samples_num=1000, negs_num_per_query=10, netvlad_clusters=64, num_workers=2, off_the_shelf='imagenet', optim='adam', patience=3, pca_dataset_folder=None, pca_dim=None, pretrain='imagenet', queries_per_epoch=5000, rand_perspective=0, random_resized_crop=0, random_rotation=0, recall_values=[1, 5, 10, 20], resize=[480, 640], resume=None, resume2=None, saturation=0, save_dir='/content/drive/MyDrive/MLDL/results/synthetic_data3/2023-02-02_12-37-00', seed=0, test_method='hard_resize', train_batch_size=4, train_positives_dist_threshold=10, trunc_te=None, val_positive_dist_threshold=25, weight_decay=0.01)
2023-02-02 12:37:00   The outputs are being saved in /content/drive/MyDrive/MLDL/results/synthetic_data3/2023-02-02_12-37-00
2023-02-02 12:37:00   Using 1 GPUs and 2 CPUs
2023-02-02 12:37:00   Loading dataset pitts30k from folder /content
2023-02-02 12:37:00   There are 72 queries without any positives within the training set. They won't be considered as they're useless for training.
2023-02-02 12:37:00   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 858 >
2023-02-02 12:37:00   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2023-02-02 12:37:00   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2023-02-02 12:37:00   Train only conv4_x of the resnetresnet18 (remove conv5_x), freeze the previous ones
2023-02-02 12:37:02   Extracting features to initialize NetVLAD layer
2023-02-02 12:37:17   NetVLAD centroids shape: (64, 256)
2023-02-02 12:37:19   Output dimension of the model is 16384, with 17.27 GFLOPs
2023-02-02 12:37:19   Start training epoch: 00
2023-02-02 12:37:19   Cache: 0 / 5
2023-02-02 12:37:19   
Traceback (most recent call last):
  File "train.py", line 123, in <module>
    triplets_ds.compute_triplets(args, model)
  File "/content/drive/MyDrive/MLDL/deep-visual-geo-localization-benchmark-main/datasets_ws.py", line 248, in compute_triplets
    self.compute_triplets_partial(args, model)
  File "/content/drive/MyDrive/MLDL/deep-visual-geo-localization-benchmark-main/datasets_ws.py", line 358, in compute_triplets_partial
    sampled_queries_indexes = np.random.choice(self.queries_num, args.cache_refresh_rate, replace=False)
  File "mtrand.pyx", line 965, in numpy.random.mtrand.RandomState.choice
ValueError: Cannot take a larger sample than population when 'replace=False'

