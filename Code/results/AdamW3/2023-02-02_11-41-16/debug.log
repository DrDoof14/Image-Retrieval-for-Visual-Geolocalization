2023-02-02 11:41:17   Arguments: Namespace(Ensembel=False, aggregation='netvlad', aggregation2='netvlad', backbone='resnet18conv4', brightness=0, cache_refresh_rate=1000, contrast=0, criterion='triplet', dataset_name='pitts30k', datasets_folder='/content/drive/MyDrive/MLDL/datasets_vg', device='cuda', efficient_ram_testing=False, epochs_num=10, fc_output_dim=None, freeze_te=None, horizontal_flip=False, hue=0, infer_batch_size=16, l2='before_pool', lr=0.0001, lr_crn_layer=0.005, lr_crn_net=0.0005, majority_weight=0.01, margin=0.1, mining='partial', neg_samples_num=1000, negs_num_per_query=10, netvlad_clusters=64, num_workers=2, off_the_shelf='imagenet', optim='AdamW', patience=3, pca_dataset_folder=None, pca_dim=None, pretrain='imagenet', queries_per_epoch=5000, rand_perspective=0, random_resized_crop=0, random_rotation=0, recall_values=[1, 5, 10, 20], resize=[480, 640], resume=None, resume2=None, saturation=0, save_dir='/content/drive/MyDrive/MLDL/results/AdamW3/2023-02-02_11-41-16', seed=0, test_method='hard_resize', train_batch_size=4, train_positives_dist_threshold=10, trunc_te=None, val_positive_dist_threshold=25, weight_decay=0.05)
2023-02-02 11:41:17   The outputs are being saved in /content/drive/MyDrive/MLDL/results/AdamW3/2023-02-02_11-41-16
2023-02-02 11:41:17   Using 1 GPUs and 2 CPUs
2023-02-02 11:41:17   Loading dataset pitts30k from folder /content/drive/MyDrive/MLDL/datasets_vg
2023-02-02 11:42:49   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2023-02-02 11:42:49   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2023-02-02 11:45:16   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2023-02-02 11:47:37   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2023-02-02 11:47:38   Train only conv4_x of the resnetresnet18 (remove conv5_x), freeze the previous ones
2023-02-02 11:47:44   Extracting features to initialize NetVLAD layer
2023-02-02 11:48:51   NetVLAD centroids shape: (64, 256)
2023-02-02 11:48:52   Output dimension of the model is 16384, with 17.27 GFLOPs
2023-02-02 11:48:52   Start training epoch: 00
2023-02-02 11:48:52   Cache: 0 / 5
2023-02-02 12:06:47   Epoch[00](0/5): current batch triplet loss = 0.0104, average epoch triplet loss = 0.0182
2023-02-02 12:06:47   Cache: 1 / 5
2023-02-02 12:14:30   Epoch[00](1/5): current batch triplet loss = 0.0024, average epoch triplet loss = 0.0162
2023-02-02 12:14:30   Cache: 2 / 5
2023-02-02 12:21:34   Epoch[00](2/5): current batch triplet loss = 0.0056, average epoch triplet loss = 0.0149
2023-02-02 12:21:34   Cache: 3 / 5
2023-02-02 12:28:28   Epoch[00](3/5): current batch triplet loss = 0.0235, average epoch triplet loss = 0.0137
2023-02-02 12:28:28   Cache: 4 / 5
2023-02-02 12:34:54   Epoch[00](4/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0127
2023-02-02 12:34:54   Finished epoch 00 in 0:46:02, average epoch triplet loss = 0.0127
2023-02-02 12:34:54   Extracting database features for evaluation/testing
2023-02-02 13:01:36   Extracting queries features for evaluation/testing
2023-02-02 13:16:17   Calculating recalls
2023-02-02 13:16:49   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.0, R@5: 95.3, R@10: 97.0, R@20: 98.0
2023-02-02 13:16:49   Improved: previous best R@5 = 0.0, current R@5 = 95.3
2023-02-02 13:16:49   Start training epoch: 01
2023-02-02 13:16:49   Cache: 0 / 5
2023-02-02 13:23:17   Epoch[01](0/5): current batch triplet loss = 0.0084, average epoch triplet loss = 0.0081
2023-02-02 13:23:17   Cache: 1 / 5
2023-02-02 13:29:41   Epoch[01](1/5): current batch triplet loss = 0.0010, average epoch triplet loss = 0.0077
2023-02-02 13:29:41   Cache: 2 / 5
2023-02-02 13:35:59   Epoch[01](2/5): current batch triplet loss = 0.0058, average epoch triplet loss = 0.0073
2023-02-02 13:35:59   Cache: 3 / 5
2023-02-02 13:41:58   Epoch[01](3/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0069
2023-02-02 13:41:58   Cache: 4 / 5
2023-02-02 13:47:42   Epoch[01](4/5): current batch triplet loss = 0.0051, average epoch triplet loss = 0.0065
2023-02-02 13:47:42   Finished epoch 01 in 0:30:53, average epoch triplet loss = 0.0065
2023-02-02 13:47:42   Extracting database features for evaluation/testing
2023-02-02 13:50:02   Extracting queries features for evaluation/testing
2023-02-02 13:51:47   Calculating recalls
2023-02-02 13:52:19   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 86.8, R@5: 95.2, R@10: 96.8, R@20: 98.0
2023-02-02 13:52:19   Not improved: 1 / 3: best R@5 = 95.3, current R@5 = 95.2
2023-02-02 13:52:19   Start training epoch: 02
2023-02-02 13:52:19   Cache: 0 / 5
2023-02-02 13:57:59   Epoch[02](0/5): current batch triplet loss = 0.0025, average epoch triplet loss = 0.0055
2023-02-02 13:57:59   Cache: 1 / 5
2023-02-02 14:03:36   Epoch[02](1/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0049
2023-02-02 14:03:36   Cache: 2 / 5
2023-02-02 14:10:03   Epoch[02](2/5): current batch triplet loss = 0.0007, average epoch triplet loss = 0.0048
2023-02-02 14:10:03   Cache: 3 / 5
2023-02-02 14:15:28   Epoch[02](3/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0046
2023-02-02 14:15:28   Cache: 4 / 5
2023-02-02 14:20:59   Epoch[02](4/5): current batch triplet loss = 0.0012, average epoch triplet loss = 0.0044
2023-02-02 14:20:59   Finished epoch 02 in 0:28:39, average epoch triplet loss = 0.0044
2023-02-02 14:20:59   Extracting database features for evaluation/testing
2023-02-02 14:23:17   Extracting queries features for evaluation/testing
2023-02-02 14:25:05   Calculating recalls
2023-02-02 14:25:36   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 86.8, R@5: 94.9, R@10: 96.7, R@20: 97.9
2023-02-02 14:25:37   Not improved: 2 / 3: best R@5 = 95.3, current R@5 = 94.9
2023-02-02 14:25:37   Start training epoch: 03
2023-02-02 14:25:37   Cache: 0 / 5
2023-02-02 14:30:56   Epoch[03](0/5): current batch triplet loss = 0.0020, average epoch triplet loss = 0.0035
2023-02-02 14:30:56   Cache: 1 / 5
2023-02-02 14:36:15   Epoch[03](1/5): current batch triplet loss = 0.0044, average epoch triplet loss = 0.0035
2023-02-02 14:36:15   Cache: 2 / 5
2023-02-02 14:41:32   Epoch[03](2/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0033
2023-02-02 14:41:32   Cache: 3 / 5
2023-02-02 14:46:49   Epoch[03](3/5): current batch triplet loss = 0.0155, average epoch triplet loss = 0.0032
2023-02-02 14:46:49   Cache: 4 / 5
2023-02-02 14:52:01   Epoch[03](4/5): current batch triplet loss = 0.0035, average epoch triplet loss = 0.0031
2023-02-02 14:52:01   Finished epoch 03 in 0:26:24, average epoch triplet loss = 0.0031
2023-02-02 14:52:01   Extracting database features for evaluation/testing
2023-02-02 14:54:19   Extracting queries features for evaluation/testing
2023-02-02 14:56:04   Calculating recalls
2023-02-02 14:56:37   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.2, R@5: 95.2, R@10: 96.7, R@20: 97.9
2023-02-02 14:56:37   Not improved: 3 / 3: best R@5 = 95.3, current R@5 = 95.2
2023-02-02 14:56:37   Performance did not improve for 3 epochs. Stop training.
2023-02-02 14:56:37   Best R@5: 95.3
2023-02-02 14:56:37   Trained for 04 epochs, in total in 3:15:20
2023-02-02 14:56:37   Extracting database features for evaluation/testing
2023-02-02 15:19:08   Extracting queries features for evaluation/testing
2023-02-02 15:31:37   Calculating recalls
2023-02-02 15:32:07   Recalls on < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >: R@1: 85.2, R@5: 92.6, R@10: 94.7, R@20: 96.5
