2023-01-29 11:07:57   Arguments: Namespace(Ensembel=False, aggregation='netvlad', aggregation2='netvlad', backbone='resnet18conv4', brightness=0, cache_refresh_rate=1000, contrast=0, criterion='triplet', dataset_name='pitts30k', datasets_folder='/content/drive/MyDrive/MLDL/datasets_vg', device='cuda', efficient_ram_testing=False, epochs_num=10, fc_output_dim=None, freeze_te=None, horizontal_flip=False, hue=0, infer_batch_size=16, l2='before_pool', lr=1e-05, lr_crn_layer=0.005, lr_crn_net=0.0005, majority_weight=0.01, margin=0.1, mining='partial', neg_samples_num=1000, negs_num_per_query=10, netvlad_clusters=64, num_workers=2, off_the_shelf='imagenet', optim='AdamW', patience=3, pca_dataset_folder=None, pca_dim=None, pretrain='imagenet', queries_per_epoch=5000, rand_perspective=0, random_resized_crop=0, random_rotation=0, recall_values=[1, 5, 10, 20], resize=[480, 640], resume=None, resume2=None, saturation=0, save_dir='/content/drive/MyDrive/MLDL/results/AdamW2/2023-01-29_11-07-57', seed=0, test_method='hard_resize', train_batch_size=4, train_positives_dist_threshold=10, trunc_te=None, val_positive_dist_threshold=25, weight_decay=0.05)
2023-01-29 11:07:57   The outputs are being saved in /content/drive/MyDrive/MLDL/results/AdamW2/2023-01-29_11-07-57
2023-01-29 11:07:57   Using 1 GPUs and 2 CPUs
2023-01-29 11:07:57   Loading dataset pitts30k from folder /content/drive/MyDrive/MLDL/datasets_vg
2023-01-29 11:07:58   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2023-01-29 11:07:58   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2023-01-29 11:08:06   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2023-01-29 11:08:09   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2023-01-29 11:08:10   Train only conv4_x of the resnetresnet18 (remove conv5_x), freeze the previous ones
2023-01-29 11:08:16   Extracting features to initialize NetVLAD layer
2023-01-29 11:08:32   NetVLAD centroids shape: (64, 256)
2023-01-29 11:08:33   Output dimension of the model is 16384, with 17.27 GFLOPs
2023-01-29 11:08:33   Start training epoch: 00
2023-01-29 11:08:33   Cache: 0 / 5
2023-01-29 11:13:37   Epoch[00](0/5): current batch triplet loss = 0.0190, average epoch triplet loss = 0.0348
2023-01-29 11:13:37   Cache: 1 / 5
2023-01-29 11:18:43   Epoch[00](1/5): current batch triplet loss = 0.0146, average epoch triplet loss = 0.0312
2023-01-29 11:18:43   Cache: 2 / 5
2023-01-29 11:23:50   Epoch[00](2/5): current batch triplet loss = 0.0364, average epoch triplet loss = 0.0297
2023-01-29 11:23:50   Cache: 3 / 5
2023-01-29 11:28:56   Epoch[00](3/5): current batch triplet loss = 0.0270, average epoch triplet loss = 0.0281
2023-01-29 11:28:56   Cache: 4 / 5
2023-01-29 11:34:03   Epoch[00](4/5): current batch triplet loss = 0.0016, average epoch triplet loss = 0.0269
2023-01-29 11:34:03   Finished epoch 00 in 0:25:30, average epoch triplet loss = 0.0269
2023-01-29 11:34:03   Extracting database features for evaluation/testing
2023-01-29 11:36:28   Extracting queries features for evaluation/testing
2023-01-29 11:38:18   Calculating recalls
2023-01-29 11:38:52   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 86.1, R@5: 95.0, R@10: 96.9, R@20: 98.2
2023-01-29 11:38:52   Improved: previous best R@5 = 0.0, current R@5 = 95.0
2023-01-29 11:38:52   Start training epoch: 01
2023-01-29 11:38:52   Cache: 0 / 5
2023-01-29 11:43:57   Epoch[01](0/5): current batch triplet loss = 0.0261, average epoch triplet loss = 0.0212
2023-01-29 11:43:57   Cache: 1 / 5
2023-01-29 11:49:04   Epoch[01](1/5): current batch triplet loss = 0.0190, average epoch triplet loss = 0.0212
2023-01-29 11:49:04   Cache: 2 / 5
2023-01-29 11:54:09   Epoch[01](2/5): current batch triplet loss = 0.0222, average epoch triplet loss = 0.0206
2023-01-29 11:54:09   Cache: 3 / 5
2023-01-29 11:59:14   Epoch[01](3/5): current batch triplet loss = 0.0104, average epoch triplet loss = 0.0198
2023-01-29 11:59:14   Cache: 4 / 5
2023-01-29 12:04:17   Epoch[01](4/5): current batch triplet loss = 0.0246, average epoch triplet loss = 0.0192
2023-01-29 12:04:17   Finished epoch 01 in 0:25:24, average epoch triplet loss = 0.0192
2023-01-29 12:04:17   Extracting database features for evaluation/testing
2023-01-29 12:06:38   Extracting queries features for evaluation/testing
2023-01-29 12:08:27   Calculating recalls
2023-01-29 12:09:01   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.3, R@5: 95.6, R@10: 97.3, R@20: 98.4
2023-01-29 12:09:01   Improved: previous best R@5 = 95.0, current R@5 = 95.6
2023-01-29 12:09:01   Start training epoch: 02
2023-01-29 12:09:01   Cache: 0 / 5
2023-01-29 12:14:06   Epoch[02](0/5): current batch triplet loss = 0.0181, average epoch triplet loss = 0.0181
2023-01-29 12:14:06   Cache: 1 / 5
2023-01-29 12:19:10   Epoch[02](1/5): current batch triplet loss = 0.0006, average epoch triplet loss = 0.0163
2023-01-29 12:19:10   Cache: 2 / 5
2023-01-29 12:24:14   Epoch[02](2/5): current batch triplet loss = 0.0091, average epoch triplet loss = 0.0165
2023-01-29 12:24:14   Cache: 3 / 5
2023-01-29 12:29:19   Epoch[02](3/5): current batch triplet loss = 0.0140, average epoch triplet loss = 0.0159
2023-01-29 12:29:19   Cache: 4 / 5
2023-01-29 12:34:24   Epoch[02](4/5): current batch triplet loss = 0.0218, average epoch triplet loss = 0.0156
2023-01-29 12:34:24   Finished epoch 02 in 0:25:22, average epoch triplet loss = 0.0156
2023-01-29 12:34:24   Extracting database features for evaluation/testing
2023-01-29 12:36:45   Extracting queries features for evaluation/testing
2023-01-29 12:38:34   Calculating recalls
2023-01-29 12:39:08   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.5, R@5: 95.6, R@10: 97.3, R@20: 98.5
2023-01-29 12:39:08   Not improved: 1 / 3: best R@5 = 95.6, current R@5 = 95.6
2023-01-29 12:39:08   Start training epoch: 03
2023-01-29 12:39:08   Cache: 0 / 5
2023-01-29 12:44:14   Epoch[03](0/5): current batch triplet loss = 0.0015, average epoch triplet loss = 0.0141
2023-01-29 12:44:14   Cache: 1 / 5
2023-01-29 12:49:19   Epoch[03](1/5): current batch triplet loss = 0.0059, average epoch triplet loss = 0.0143
2023-01-29 12:49:19   Cache: 2 / 5
2023-01-29 12:54:25   Epoch[03](2/5): current batch triplet loss = 0.0048, average epoch triplet loss = 0.0141
2023-01-29 12:54:25   Cache: 3 / 5
2023-01-29 12:59:29   Epoch[03](3/5): current batch triplet loss = 0.0301, average epoch triplet loss = 0.0137
2023-01-29 12:59:29   Cache: 4 / 5
2023-01-29 13:04:35   Epoch[03](4/5): current batch triplet loss = 0.0230, average epoch triplet loss = 0.0133
2023-01-29 13:04:35   Finished epoch 03 in 0:25:26, average epoch triplet loss = 0.0133
2023-01-29 13:04:35   Extracting database features for evaluation/testing
2023-01-29 13:06:58   Extracting queries features for evaluation/testing
2023-01-29 13:08:47   Calculating recalls
2023-01-29 13:09:21   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 88.0, R@5: 95.8, R@10: 97.5, R@20: 98.6
2023-01-29 13:09:21   Improved: previous best R@5 = 95.6, current R@5 = 95.8
2023-01-29 13:09:21   Start training epoch: 04
2023-01-29 13:09:21   Cache: 0 / 5
2023-01-29 13:13:02   
Traceback (most recent call last):
  File "train.py", line 135, in <module>
    # triplets_local_indexes shape: (train_batch_size*10)*3 ; because 10 triplets per query
  File "/usr/local/lib/python3.8/dist-packages/tqdm/std.py", line 1205, in __iter__
    self.update(n - last_print_n)
  File "/usr/local/lib/python3.8/dist-packages/tqdm/std.py", line 1256, in update
    self.refresh(lock_args=self.lock_args)
  File "/usr/local/lib/python3.8/dist-packages/tqdm/std.py", line 1361, in refresh
    self.display()
  File "/usr/local/lib/python3.8/dist-packages/tqdm/std.py", line 1509, in display
    self.sp(self.__str__() if msg is None else msg)
  File "/usr/local/lib/python3.8/dist-packages/tqdm/std.py", line 349, in print_status
    len_s = disp_len(s)
  File "/usr/local/lib/python3.8/dist-packages/tqdm/utils.py", line 338, in disp_len
    return _text_width(RE_ANSI.sub('', data))
  File "/usr/local/lib/python3.8/dist-packages/tqdm/utils.py", line 330, in _text_width
    return sum(2 if east_asian_width(ch) in 'FW' else 1 for ch in _unicode(s))
  File "/usr/local/lib/python3.8/dist-packages/tqdm/utils.py", line 330, in <genexpr>
    return sum(2 if east_asian_width(ch) in 'FW' else 1 for ch in _unicode(s))
KeyboardInterrupt

