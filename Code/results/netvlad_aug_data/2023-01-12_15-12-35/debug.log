2023-01-12 15:12:35   Arguments: Namespace(aggregation='netvlad', backbone='resnet18conv4', brightness=0, brightness_factor_max=0.3, brightness_factor_min=0.1, cache_refresh_rate=1000, contrast=0, criterion='triplet', dataset_name='pitts30k', datasets_folder='/content/drive/MyDrive/MLDL/datasets_vg', device='cuda', efficient_ram_testing=False, epochs_num=11, fc_output_dim=None, freeze_te=None, horizontal_flip=False, hue=0, infer_batch_size=16, l2='before_pool', lr=1e-05, lr_crn_layer=0.005, lr_crn_net=0.0005, majority_weight=0.01, margin=0.1, mining='partial', neg_samples_num=1000, negs_num_per_query=10, netvlad_clusters=64, num_workers=2, off_the_shelf='imagenet', optim='adam', patience=3, pca_dataset_folder=None, pca_dim=None, pretrain='imagenet', queries_per_epoch=5000, rand_perspective=0, random_resized_crop=0, random_rotation=0, recall_values=[1, 5, 10, 20], resize=[480, 640], resume='/content/drive/MyDrive/MLDL/results/base_netvlad/resume_training/2023-01-12_09-09-47/best_model.pth', saturation=0, save_dir='/content/drive/MyDrive/MLDL/results/netvlad_aug_data/2023-01-12_15-12-35', seed=0, test_method='hard_resize', train_batch_size=4, train_positives_dist_threshold=10, trunc_te=None, val_positive_dist_threshold=25)
2023-01-12 15:12:35   The outputs are being saved in /content/drive/MyDrive/MLDL/results/netvlad_aug_data/2023-01-12_15-12-35
2023-01-12 15:12:35   Using 1 GPUs and 2 CPUs
2023-01-12 15:12:35   Loading dataset pitts30k from folder /content/drive/MyDrive/MLDL/datasets_vg
2023-01-12 15:12:36   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2023-01-12 15:12:36   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2023-01-12 15:12:37   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2023-01-12 15:12:40   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2023-01-12 15:12:40   Train only conv4_x of the resnetresnet18 (remove conv5_x), freeze the previous ones
2023-01-12 15:12:43   Loading checkpoint: /content/drive/MyDrive/MLDL/results/base_netvlad/resume_training/2023-01-12_09-09-47/best_model.pth
2023-01-12 15:12:43   Loaded checkpoint: start_epoch_num = 6, current_best_R@5 = 96.0
2023-01-12 15:12:43   Resuming from epoch 6 with best recall@5 96.0
2023-01-12 15:12:45   Output dimension of the model is 16384, with 17.33 GFLOPs
2023-01-12 15:12:45   Start training epoch: 06
2023-01-12 15:12:45   Cache: 0 / 5
2023-01-12 15:18:50   Epoch[06](0/5): current batch triplet loss = 0.0379, average epoch triplet loss = 0.0615
2023-01-12 15:18:50   Cache: 1 / 5
2023-01-12 15:31:06   Epoch[06](1/5): current batch triplet loss = 0.0341, average epoch triplet loss = 0.0565
2023-01-12 15:31:06   Cache: 2 / 5
2023-01-12 15:42:40   Epoch[06](2/5): current batch triplet loss = 0.0314, average epoch triplet loss = 0.0533
2023-01-12 15:42:40   Cache: 3 / 5
2023-01-12 15:53:14   Epoch[06](3/5): current batch triplet loss = 0.0548, average epoch triplet loss = 0.0513
2023-01-12 15:53:14   Cache: 4 / 5
2023-01-12 16:03:04   Epoch[06](4/5): current batch triplet loss = 0.0341, average epoch triplet loss = 0.0500
2023-01-12 16:03:04   Finished epoch 06 in 0:50:19, average epoch triplet loss = 0.0500
2023-01-12 16:03:04   Extracting database features for evaluation/testing
2023-01-12 17:00:03   Extracting queries features for evaluation/testing
2023-01-12 17:56:21   Calculating recalls
2023-01-12 17:56:55   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.9, R@5: 95.6, R@10: 97.1, R@20: 98.2
2023-01-12 17:56:55   Not improved: 2 / 3: best R@5 = 96.0, current R@5 = 95.6
2023-01-12 17:56:55   Start training epoch: 07
2023-01-12 17:56:55   Cache: 0 / 5
2023-01-12 18:06:12   
Traceback (most recent call last):
  File "train.py", line 132, in <module>
    for images, triplets_local_indexes, _ in tqdm(triplets_dl, ncols=100):
  File "/usr/local/lib/python3.8/dist-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 1316, in _next_data
    idx, data = self._get_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 1272, in _get_data
    success, data = self._try_get_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 1120, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/usr/lib/python3.8/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/usr/lib/python3.8/threading.py", line 306, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt

