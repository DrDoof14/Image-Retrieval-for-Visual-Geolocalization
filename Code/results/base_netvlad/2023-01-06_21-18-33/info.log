2023-01-06 21:18:34   Arguments: Namespace(aggregation='netvlad', backbone='resnet18conv4', brightness=0, cache_refresh_rate=1000, contrast=0, criterion='triplet', dataset_name='pitts30k', datasets_folder='/content/drive/MyDrive/MLDL/datasets_vg', device='cuda', efficient_ram_testing=False, epochs_num=10, fc_output_dim=None, freeze_te=None, horizontal_flip=False, hue=0, infer_batch_size=16, l2='before_pool', lr=1e-05, lr_crn_layer=0.005, lr_crn_net=0.0005, majority_weight=0.01, margin=0.1, mining='partial', neg_samples_num=1000, negs_num_per_query=10, netvlad_clusters=64, num_workers=2, off_the_shelf='imagenet', optim='adam', patience=3, pca_dataset_folder=None, pca_dim=None, pretrain='imagenet', queries_per_epoch=5000, rand_perspective=0, random_resized_crop=0, random_rotation=0, recall_values=[1, 5, 10, 20], resize=[480, 640], resume=None, saturation=0, save_dir='/content/drive/MyDrive/MLDL/results/base_netvlad/2023-01-06_21-18-33', seed=0, test_method='hard_resize', train_batch_size=4, train_positives_dist_threshold=10, trunc_te=None, val_positive_dist_threshold=25)
2023-01-06 21:18:34   The outputs are being saved in /content/drive/MyDrive/MLDL/results/base_netvlad/2023-01-06_21-18-33
2023-01-06 21:18:34   Using 1 GPUs and 2 CPUs
2023-01-06 21:19:56   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2023-01-06 21:19:56   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2023-01-06 21:21:04   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2023-01-06 21:22:14   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2023-01-06 21:25:58   Output dimension of the model is 16384, with 17.27 GFLOPs
2023-01-06 21:25:58   Start training epoch: 00
2023-01-06 22:52:12   Finished epoch 00 in 1:26:14, average epoch triplet loss = 0.0269
2023-01-06 23:29:13   
Traceback (most recent call last):
  File "train.py", line 184, in <module>
    recalls, recalls_str = test.test(args, val_ds, model)
  File "/content/drive/MyDrive/MLDL/deep-visual-geo-localization-benchmark-main/test.py", line 144, in test
  File "/usr/local/lib/python3.8/dist-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/usr/local/lib/python3.8/dist-packages/torch/_utils.py", line 543, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py", line 295, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/content/drive/MyDrive/MLDL/deep-visual-geo-localization-benchmark-main/datasets_ws.py", line 106, in __getitem__
  File "/content/drive/MyDrive/MLDL/deep-visual-geo-localization-benchmark-main/datasets_ws.py", line 25, in path_to_pil_img
  File "/usr/local/lib/python3.8/dist-packages/PIL/Image.py", line 2843, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/MLDL/datasets_vg/pitts30k/images/val/database/@0585071.09@4476976.69@17@T@040.43908@-079.99693@000122@35@@@@@@pitch2_yaw12@.jpg'


